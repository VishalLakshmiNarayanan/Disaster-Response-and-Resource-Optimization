# -*- coding: utf-8 -*-
"""FSE570_data_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XYkQcv7F5453vtuKqshl8Pbc_Kq9SwAv
"""

# libraries
from google.colab import files
import pandas as pd
import json

uploaded = files.upload()

df_unemp = pd.read_csv("Unemployment2023.csv")
df_pov = pd.read_csv("Poverty2023.csv")
df_pop = pd.read_csv("PopulationEstimates.csv", encoding="latin1")
df_time = pd.read_csv("time-series.csv")

df_events = pd.read_csv(
    "events-US-1980-2024.csv", skiprows=2, encoding="latin1"
)

with open("DisasterDeclarationsSummaries.json") as f:
    data = json.load(f)
df_fema = pd.json_normalize(data["DisasterDeclarationsSummaries"])

# removing records where Area names don't have commas, to get county level records
# filters 329726 entries to 324438
df_unemp_filtered = df_unemp[df_unemp['Area_Name'].str.contains(",")]

# removing aggregated rows like 'United States' or inidivual state names to get county records
# filtered from 79934 records to 78325 records
df_pov_filtered = df_pov[df_pov["Area_Name"] != "United States"]
df_pov_filtered = df_pov_filtered[
    df_pov_filtered["Area_Name"].str.contains(
        "County|Parish|Borough|Census Area|city|Municipality",
        case=False,
        regex=True
    )
]

# removing aggregated rows like 'United States' or inidivual state names to get county records
# filtered df from 208225 records to 203736 records
df_pop_filtered = df_pop[df_pop["Area_Name"] != "United States"]
df_pop_filtered = df_pop_filtered[
    df_pop_filtered["Area_Name"].str.contains(
        "County|Parish|Borough|Census Area|city|Municipality",
        case=False,
        regex=True
    )
]

# get the full county code
df_fema["FIPS_Code"] = (
    df_fema["fipsStateCode"].str.zfill(2) +
    df_fema["fipsCountyCode"].str.zfill(3)
)